{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9evB5XilWeV",
    "outputId": "d3dd20e4-146c-42c0-c23c-9c3b198c2723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7g4Ikm7naCVQ",
    "outputId": "af4155c1-5218-405e-8198-1ec877647992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sskfZBokaD3W",
    "outputId": "3afc8112-9399-4296-ef2c-9f0cf6680734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.0.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.11.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUQO9kmAmCgF",
    "outputId": "9696e804-5a88-4daf-d199-ccb9df96734e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uGxCVJFmXFb",
    "outputId": "bd579ae1-8126-433e-e9c9-7e14713ea2c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.1.1-cp310-none-win_amd64.whl (73.9 MB)\n",
      "     --------------------------------------- 73.9/73.9 MB 32.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\aman\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.0/47.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\aman\\anaconda3\\lib\\site-packages (from catboost) (1.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\aman\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aman\\anaconda3\\lib\\site-packages (from catboost) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (22.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\aman\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.1.1 graphviz-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kAU-TiT3l-9F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from transformers import pipeline\n",
    "from gensim.models import Word2Vec\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HFbOFh4EaO5n"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"cleaned_train.csv\")\n",
    "test_df= pd.read_csv(\"cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "M0WnWGRZmvgu",
    "outputId": "7215569c-f251-45a4-b555-eec937bce94d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "      <td>opaque eyelets fading office curtainluxurious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "      <td>hedwig spencer 98 marks elastane harry exclusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td>pump 12v v compatible aluminum 130db vehicles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td>chart fabric lycra ankel may 2aishah pack legg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>like 02cm home makes better holder planter all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_TYPE_ID  PRODUCT_LENGTH  \\\n",
       "0             1650     2125.980000   \n",
       "1             2755      393.700000   \n",
       "2             7537      748.031495   \n",
       "3             2996      787.401574   \n",
       "4             5725      950.000000   \n",
       "\n",
       "                                                text  \n",
       "0  opaque eyelets fading office curtainluxurious ...  \n",
       "1  hedwig spencer 98 marks elastane harry exclusi...  \n",
       "2  pump 12v v compatible aluminum 130db vehicles ...  \n",
       "3  chart fabric lycra ankel may 2aishah pack legg...  \n",
       "4  like 02cm home makes better holder planter all...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text']=train_df['text'].astype(str)\n",
    "test_df['text']=test_df['text'].astype(str)\n",
    "train_df = train_df.dropna()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oqA_YzVXnS7K"
   },
   "outputs": [],
   "source": [
    "prod_id=test_df['PRODUCT_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0SqWBabsnhoZ",
    "outputId": "2acb5849-5089-4eb5-ce2c-7cf202aae474"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>6142</td>\n",
       "      <td>hliogravure relief traditions d1890 savoirs de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>1622</td>\n",
       "      <td>fleece low chart hand fabric microfiber medita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>7540</td>\n",
       "      <td>2018 2020 auto holder nx300 textured fit numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>12442</td>\n",
       "      <td>3mm includes lapel award andgold longtime pin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>6318</td>\n",
       "      <td>ti89 mathematics visual ti92 illustrated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  PRODUCT_TYPE_ID  \\\n",
       "0      604373             6142   \n",
       "1     1729783             1622   \n",
       "2     1871949             7540   \n",
       "3     1107571            12442   \n",
       "4      624253             6318   \n",
       "\n",
       "                                                text  \n",
       "0  hliogravure relief traditions d1890 savoirs de...  \n",
       "1  fleece low chart hand fabric microfiber medita...  \n",
       "2  2018 2020 auto holder nx300 textured fit numbe...  \n",
       "3  3mm includes lapel award andgold longtime pin ...  \n",
       "4           ti89 mathematics visual ti92 illustrated  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eL4ZY2nbnkdE"
   },
   "outputs": [],
   "source": [
    "test_df=test_df.drop('PRODUCT_ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nBS4UaS4nmYf",
    "outputId": "5c534dbd-ca26-4f07-cb3c-0b4d6f0072f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "      <td>opaque eyelets fading office curtainluxurious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "      <td>hedwig spencer 98 marks elastane harry exclusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td>pump 12v v compatible aluminum 130db vehicles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td>chart fabric lycra ankel may 2aishah pack legg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>like 02cm home makes better holder planter all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_TYPE_ID  PRODUCT_LENGTH  \\\n",
       "0             1650     2125.980000   \n",
       "1             2755      393.700000   \n",
       "2             7537      748.031495   \n",
       "3             2996      787.401574   \n",
       "4             5725      950.000000   \n",
       "\n",
       "                                                text  \n",
       "0  opaque eyelets fading office curtainluxurious ...  \n",
       "1  hedwig spencer 98 marks elastane harry exclusi...  \n",
       "2  pump 12v v compatible aluminum 130db vehicles ...  \n",
       "3  chart fabric lycra ankel may 2aishah pack legg...  \n",
       "4  like 02cm home makes better holder planter all...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6grS5ge9nnyM",
    "outputId": "00ac87f7-53d3-4cdf-a456-546c2172221e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = [token for token in text.split() if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs_train = train_df['text'].apply(preprocess)\n",
    "processed_docs_test = test_df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SiMoK_-3nrbn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1439.3289306163788 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model = Word2Vec(processed_docs_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"Time taken:\", time_taken, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P59hunRYnx9E"
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for sent in processed_docs_train:\n",
    "  string = ' '.join(sent)\n",
    "  l.append(string)\n",
    "train_df['PROCESSED_TITLE'] = l\n",
    "\n",
    "\n",
    "\n",
    "l = []\n",
    "for sent in processed_docs_test:\n",
    "  string = ' '.join(sent)\n",
    "  l.append(string)\n",
    "test_df['PROCESSED_TITLE'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tvb4mWiqnySO"
   },
   "outputs": [],
   "source": [
    "train_df=train_df.drop('text',axis=1)\n",
    "test_df=test_df.drop('text',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CPi-Q0RenyUd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sentence_embedding(sentence):\n",
    "    words = [word.strip(\",.\") for word in sentence.split()]\n",
    "    #wlist = preprocess(sentence)\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv.key_to_index]\n",
    "    if len(vectors) == 0:\n",
    "         return np.zeros(model.vector_size)\n",
    "    else:\n",
    "         return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MLytmYb7nyX2"
   },
   "outputs": [],
   "source": [
    "train_df['TITLE_EMBED'] = train_df['PROCESSED_TITLE'].apply(sentence_embedding)\n",
    "test_df['TITLE_EMBED'] = test_df['PROCESSED_TITLE'].apply(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LKiSmZeanyaV"
   },
   "outputs": [],
   "source": [
    "y_train=train_df['PRODUCT_LENGTH']\n",
    "X_train=train_df.drop(columns=['PROCESSED_TITLE','PRODUCT_LENGTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lxUQFZutnyb2"
   },
   "outputs": [],
   "source": [
    "test_df=test_df.drop('PROCESSED_TITLE',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyU71GIQnydV"
   },
   "outputs": [],
   "source": [
    "append_func = lambda row: np.append(row['TITLE_EMBED'], row['PRODUCT_TYPE_ID'])\n",
    "\n",
    "# apply the lambda function to the 'numpy_array' column using the apply method\n",
    "X_train['appended_array'] = train_df.apply(append_func, axis=1)\n",
    "test_df['appended_array'] = test_df.apply(append_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DJT9NXroEDB"
   },
   "outputs": [],
   "source": [
    "X_train=X_train['appended_array'].to_numpy()\n",
    "test_df=test_df['appended_array'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR8Og3HDoD8y"
   },
   "outputs": [],
   "source": [
    "X_train=np.stack(X_train)\n",
    "test_df=np.stack(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcJM6ZaXoDxr"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model=CatBoostRegressor(iterations=1500,depth=10,learning_rate=0.03,loss_function=\"MAPE\")\n",
    "model.fit(X_train,y_train,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7frPSPKpQFP"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQxMbXEAppHm"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'PRODUCT_ID': prod_id, 'PRODUCT_LENGTH': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhfWNL5yppAu"
   },
   "outputs": [],
   "source": [
    "submission_df.set_index('PRODUCT_ID',inplace=True)\n",
    "submission_df.to_csv('sample_submission10.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
