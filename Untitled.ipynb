{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4138efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "#df = pd.read_csv('/content/drive/MyDrive/datasetb2d9982/dataset/test11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f4ba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1925202</td>\n",
       "      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n",
       "      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2673191</td>\n",
       "      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n",
       "      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
       "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
       "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283658</td>\n",
       "      <td>The United Empire Loyalists: A Chronicle of th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6112</td>\n",
       "      <td>598.424000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE  \\\n",
       "0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n",
       "1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n",
       "2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "4      283658  The United Empire Loyalists: A Chronicle of th...   \n",
       "\n",
       "                                       BULLET_POINTS  \\\n",
       "0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n",
       "1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n",
       "2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
       "3  [Made By 95%cotton and 5% Lycra which gives yo...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "0                                                NaN             1650   \n",
       "1                                                NaN             2755   \n",
       "2  Specifications: Color: Red, Material: Aluminiu...             7537   \n",
       "3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
       "4                                                NaN             6112   \n",
       "\n",
       "   PRODUCT_LENGTH  \n",
       "0     2125.980000  \n",
       "1      393.700000  \n",
       "2      748.031495  \n",
       "3      787.401574  \n",
       "4      598.424000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec6da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 12\n",
      "Number of empty values: 0\n",
      "Number of missing values: 0\n",
      "Number of empty values: 0\n",
      "Number of missing values: 5\n",
      "Number of empty values: 0\n",
      "Number of missing values: 0\n",
      "Number of empty values: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values\n",
    "num_missing = train_df['TITLE'].isna().sum()\n",
    "print('Number of missing values:', num_missing)\n",
    "\n",
    "# Count the number of empty values\n",
    "num_empty = (train_df['TITLE'].str.isspace()).sum()\n",
    "print('Number of empty values:', num_empty)\n",
    "\n",
    "train_df=train_df[~train_df['TITLE'].isna()]\n",
    "\n",
    "num_missing = train_df['TITLE'].isna().sum()\n",
    "print('Number of missing values:', num_missing)\n",
    "\n",
    "# Count the number of empty values\n",
    "num_empty = (train_df['TITLE'].str.isspace()).sum()\n",
    "print('Number of empty values:', num_empty)\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of missing values\n",
    "num_missing = test_df['TITLE'].isna().sum()\n",
    "print('Number of missing values:', num_missing)\n",
    "\n",
    "# Count the number of empty values\n",
    "num_empty = (test_df['TITLE'].str.isspace()).sum()\n",
    "print('Number of empty values:', num_empty)\n",
    "\n",
    "test_df=test_df[~test_df['TITLE'].isna()]\n",
    "\n",
    "num_missing = test_df['TITLE'].isna().sum()\n",
    "print('Number of missing values:', num_missing)\n",
    "\n",
    "# Count the number of empty values\n",
    "num_empty = (test_df['TITLE'].str.isspace()).sum()\n",
    "print('Number of empty values:', num_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625c57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f8e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TITLE']=train_df['TITLE'].astype(str)\n",
    "test_df['TITLE']=test_df['TITLE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c01d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sm048\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = simple_preprocess(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_docs_train = train_df['TITLE'].apply(preprocess)\n",
    "processed_docs_test = test_df['TITLE'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7e8126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 195.5919451713562 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model = Word2Vec(processed_docs_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"Time taken:\", time_taken, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114f87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for sent in processed_docs_train:\n",
    "  string = ' '.join(sent)\n",
    "  l.append(string)\n",
    "train_df['PROCESSED_TITLE'] = l\n",
    "\n",
    "\n",
    "\n",
    "l = []\n",
    "for sent in processed_docs_test:\n",
    "  string = ' '.join(sent)\n",
    "  l.append(string)\n",
    "test_df['PROCESSED_TITLE'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882d4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ArtzFolio Tulip Flowers Blackout Curtain for D...\n",
       "1          Marks & Spencer Girls' Pyjama Sets T86_2561C_N...\n",
       "2          PRIKNIK Horn Red Electric Air Horn Compressor ...\n",
       "3          ALISHAH Women's Cotton Ankle Length Leggings C...\n",
       "4          The United Empire Loyalists: A Chronicle of th...\n",
       "                                 ...                        \n",
       "2249693    Nike Women's As W Ny Df Swsh Hn Kh Bra (CZ7610...\n",
       "2249694    (3PCS) Goose Game Cute Cartoon Enamel Pins, Fu...\n",
       "2249695    Kangroo Sweep Movement Printed Wooden Wall Clo...\n",
       "2249696    Electro Voice EKX-BRKT15 | Wall Mount Bracket ...\n",
       "2249697    Skyjacker C7360SP Component Box For PN[C7360PK...\n",
       "Name: TITLE, Length: 2249686, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d388ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Manuel d'Héliogravure Et de Photogravure En Re...\n",
       "1         DCGARING Microfiber Throw Blanket Warm Fuzzy P...\n",
       "2         I-Match Auto Parts Front License Plate Bracket...\n",
       "3         PinMart Gold Plated Excellence in Service 1 Ye...\n",
       "4         Visual Mathematics, Illustrated by the TI-92 a...\n",
       "                                ...                        \n",
       "734731    Casual Canine Basic Hoodie for Dogs, 16\" Mediu...\n",
       "734732    Dive Log Book: Scuba Diving Logbook for Beginn...\n",
       "734733    Axor 39135001 Citterio Widespread Faucet with ...\n",
       "734734    Caroline's Treasures BB1801DS812 Halloween Bas...\n",
       "734735    Amsahr 18C1623 Lexmark X3530 Remanufactured Re...\n",
       "Name: TITLE, Length: 734731, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb125ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.1012301 ,  0.3854335 , -1.4557735 ,  0.47870302,  0.12572236,\n",
       "       -1.8243376 ,  0.1067934 ,  0.6609827 , -0.8741556 , -1.4668696 ,\n",
       "        0.15358666, -1.8369735 , -1.200232  ,  1.6486677 , -2.0376868 ,\n",
       "       -2.416858  , -0.42197198, -0.45723775,  1.6559204 ,  0.2643146 ,\n",
       "        1.2518744 , -0.75747657, -2.3090034 ,  0.32371235,  1.6408023 ,\n",
       "       -2.9054182 ,  0.5444453 , -0.06923099, -1.8623703 , -0.6409973 ,\n",
       "        0.12002768, -1.0224277 ,  0.2804675 , -1.6099952 , -0.22220838,\n",
       "        1.363329  ,  1.7576605 , -2.215908  , -0.9775363 , -0.3856584 ,\n",
       "        0.10552204, -0.38238052, -1.238267  , -0.273734  ,  2.5888839 ,\n",
       "       -1.899565  , -1.045925  ,  0.2620222 ,  0.1287217 , -1.1610757 ,\n",
       "        1.1247535 , -0.60129446, -1.9158392 , -1.0472008 , -0.04886642,\n",
       "       -0.60762805, -0.54098654, -0.25181863,  0.633705  ,  0.7166663 ,\n",
       "        2.4612741 ,  1.6391027 , -1.0773087 ,  2.0108821 , -1.5307118 ,\n",
       "        1.2684196 ,  1.9391242 , -1.2585177 , -1.3368087 ,  1.0866507 ,\n",
       "        0.27036646, -1.351154  , -0.03726437, -2.4861593 , -0.15332928,\n",
       "        1.8505777 , -0.38941157,  0.6086988 ,  0.6600097 ,  0.28697607,\n",
       "       -2.4307482 ,  0.3953616 ,  0.46190327, -0.85966843, -0.36499754,\n",
       "        1.5814779 ,  0.48639882,  0.30447417,  2.4004815 ,  0.89765275,\n",
       "        2.0021815 ,  1.2110568 , -0.24462435,  0.49482507,  0.7940665 ,\n",
       "       -0.46696392, -1.3682351 , -0.2718345 ,  0.25494564,  0.26713377],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['marks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "723ba78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sentence_embedding(sentence):\n",
    "    words = [word.strip(\",.\") for word in sentence.split()]\n",
    "    #wlist = preprocess(sentence)\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv.key_to_index]\n",
    "    if len(vectors) == 0:\n",
    "         return np.zeros(model.vector_size)\n",
    "    else:\n",
    "         return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bdb07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['TITLE_EMBED'] = train_df['PROCESSED_TITLE'].apply(sentence_embedding)\n",
    "test_df['TITLE_EMBED'] = test_df['PROCESSED_TITLE'].apply(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dffd35c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>PROCESSED_TITLE</th>\n",
       "      <th>TITLE_EMBED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1925202</td>\n",
       "      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n",
       "      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650</td>\n",
       "      <td>2125.980000</td>\n",
       "      <td>artzfolio tulip flowers blackout curtain door ...</td>\n",
       "      <td>[0.30626097, -0.06386575, -0.107849896, -0.790...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2673191</td>\n",
       "      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n",
       "      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2755</td>\n",
       "      <td>393.700000</td>\n",
       "      <td>marks spencer girls pyjama sets t_c_navy mix_y</td>\n",
       "      <td>[-0.36015764, -0.2353291, -0.5347107, -0.30940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n",
       "      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td>priknik horn red electric air horn compressor ...</td>\n",
       "      <td>[-1.500334, -1.3554665, 0.94741386, -0.6738702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n",
       "      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td>alishah womens cotton ankle length leggings co...</td>\n",
       "      <td>[-0.13753465, -0.2289452, 0.0760798, -1.398452...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283658</td>\n",
       "      <td>The United Empire Loyalists: A Chronicle of th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6112</td>\n",
       "      <td>598.424000</td>\n",
       "      <td>united empire loyalists chronicle great migration</td>\n",
       "      <td>[0.89516276, 0.90649396, -0.5293002, -0.757478...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE  \\\n",
       "0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n",
       "1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n",
       "2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "4      283658  The United Empire Loyalists: A Chronicle of th...   \n",
       "\n",
       "                                       BULLET_POINTS  \\\n",
       "0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n",
       "1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n",
       "2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n",
       "3  [Made By 95%cotton and 5% Lycra which gives yo...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "0                                                NaN             1650   \n",
       "1                                                NaN             2755   \n",
       "2  Specifications: Color: Red, Material: Aluminiu...             7537   \n",
       "3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n",
       "4                                                NaN             6112   \n",
       "\n",
       "   PRODUCT_LENGTH                                    PROCESSED_TITLE  \\\n",
       "0     2125.980000  artzfolio tulip flowers blackout curtain door ...   \n",
       "1      393.700000     marks spencer girls pyjama sets t_c_navy mix_y   \n",
       "2      748.031495  priknik horn red electric air horn compressor ...   \n",
       "3      787.401574  alishah womens cotton ankle length leggings co...   \n",
       "4      598.424000  united empire loyalists chronicle great migration   \n",
       "\n",
       "                                         TITLE_EMBED  \n",
       "0  [0.30626097, -0.06386575, -0.107849896, -0.790...  \n",
       "1  [-0.36015764, -0.2353291, -0.5347107, -0.30940...  \n",
       "2  [-1.500334, -1.3554665, 0.94741386, -0.6738702...  \n",
       "3  [-0.13753465, -0.2289452, 0.0760798, -1.398452...  \n",
       "4  [0.89516276, 0.90649396, -0.5293002, -0.757478...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81913db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['TITLE_EMBED'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b108df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2249686 entries, 0 to 2249697\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   PRODUCT_ID       int64  \n",
      " 1   TITLE            object \n",
      " 2   BULLET_POINTS    object \n",
      " 3   DESCRIPTION      object \n",
      " 4   PRODUCT_TYPE_ID  int64  \n",
      " 5   PRODUCT_LENGTH   float64\n",
      " 6   PROCESSED_TITLE  object \n",
      " 7   TITLE_EMBED      object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 154.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0515a6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 734731 entries, 0 to 734735\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   PRODUCT_ID       734731 non-null  int64 \n",
      " 1   TITLE            734731 non-null  object\n",
      " 2   BULLET_POINTS    458812 non-null  object\n",
      " 3   DESCRIPTION      354734 non-null  object\n",
      " 4   PRODUCT_TYPE_ID  734731 non-null  int64 \n",
      " 5   PROCESSED_TITLE  734731 non-null  object\n",
      " 6   TITLE_EMBED      734731 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3119d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_type_id=test_df['PRODUCT_ID']\n",
    "cols=['PRODUCT_ID','TITLE','BULLET_POINTS','DESCRIPTION','PROCESSED_TITLE']\n",
    "train_df.drop(columns=cols,inplace=True)\n",
    "test_df.drop(columns=cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "662e598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a lambda function to append the numeric value to the numpy array\n",
    "append_func = lambda row: np.append(row['TITLE_EMBED'], row['PRODUCT_TYPE_ID'])\n",
    "\n",
    "# apply the lambda function to the 'numpy_array' column using the apply method\n",
    "train_df['appended_array'] = train_df.apply(append_func, axis=1)\n",
    "test_df['appended_array'] = test_df.apply(append_func, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d00fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2249686 entries, 0 to 2249697\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   PRODUCT_TYPE_ID  int64  \n",
      " 1   PRODUCT_LENGTH   float64\n",
      " 2   TITLE_EMBED      object \n",
      " 3   appended_array   object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 85.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5570de60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 734731 entries, 0 to 734735\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   PRODUCT_TYPE_ID  734731 non-null  int64 \n",
      " 1   TITLE_EMBED      734731 non-null  object\n",
      " 2   appended_array   734731 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 38.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8029cc29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df['appended_array'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf0a1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df['appended_array'].to_numpy()\n",
    "y_train=train_df['PRODUCT_LENGTH'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25727347",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'appended_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'appended_array'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_df\u001b[38;5;241m=\u001b[39m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappended_array\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'appended_array'"
     ]
    }
   ],
   "source": [
    "test_df=test_df['appended_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a85e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8f36fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.stack(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f16a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=np.stack(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e813761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb8ccc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['PRODUCT_ID']=prod_type_id\n",
    "submission_df['PRODUCT_LENGTH']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f91ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.set_index('PRODUCT_ID',inplace=True)\n",
    "submission_df.to_csv('sample_submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68b1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd274c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
